<!DOCTYPE html><html lang="zh-CN"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="author" content="1-riverfish"><title>Scrapy食用指南3 · Ginger's blog</title><meta name="description" content="Scrapy文档笔记-3Scrapy shellThe Scrapy shell是一个交互式shell,你可以用它来快速地debug你的scraping代码(主要是数据提取部分)而不必运行你的爬虫.
这个Shell主要用来测试XPath或者CSS表达式并且观察它们如何工作并且数据是如何从你爬取的we"><meta name="keywords" content=""><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="renderer" content="webkit"><link rel="short icon" href="/images/favicon.png" type="image/x-icon"><link rel="stylesheet" href="/css/bootstrap.min.css"><link rel="stylesheet" href="/css/font-awesome.min.css"><link rel="stylesheet" href="/css/style.css"><link rel="alternate" type="application/atom+xml" title="ATOM 1.0" href="/atom.xml"></head><body><div id="stage" class="container"><div class="row"><div id="side-bar" class="col-sm-3 col-xs-12 side-container invisible"><div class="vertical-text site-title"><h3 tabindex="-1" class="site-title-small"><a href="/" class="a-title">Share&amp;Joy</a></h3><h1 tabindex="-1" class="site-title-large"><a href="/" class="a-title">Ginger' Blog</a></h1><!--h6(onclick="triggerSiteNav()") Trigger--></div><br class="visible-lg visible-md visible-sm"><div id="site-nav" class="site-title-links"><ul><li><a href="/">首页</a></li><li><a href="/archives">归档</a></li><li><a href="/tags">标签</a></li><li class="soc"><a href="https://github.com/1-riverfish" target="_blank" rel="noopener noreferrer"><i class="fa fa-github">&nbsp;</i></a><a href="http://yoursite.com/atom.xml" target="_blank" rel="noopener noreferrer"><i class="fa fa-rss">&nbsp;</i></a></li></ul><div class="visible-lg visible-md visible-sm site-nav-footer"><br class="site-nav-footer-br"><footer><p>&copy;&nbsp;2018&nbsp;<a target="_blank" href="http://yoursite.com" rel="noopener noreferrer">1-riverfish</a></p><p>Theme&nbsp;<a target="_blank" href="https://github.com/SumiMakito/hexo-theme-typography" rel="noopener noreferrer">Typography</a>&nbsp;by&nbsp;<a target="_blank" href="https://www.keep.moe" rel="noopener noreferrer">Makito</a></p><p>Proudly published with&nbsp;<a target="_blank" href="https://hexo.io" rel="noopener noreferrer">Hexo</a></p></footer></div></div></div><div id="main-container" class="col-sm-9 col-xs-12 main-container invisible"><div class="autopagerize_page_element"><div class="content"><div class="post-page"><div class="post-container"><p class="post-title"><a>Scrapy食用指南3</a></p><p class="post-meta"><span class="date meta-item">发布于&nbsp;2018-05-29</span><span class="meta-item"><i class="fa fa-tag"></i><span>&nbsp;</span><a href="/tags/Scrapy/" title="Scrapy" class="a-tag">Scrapy</a><span>&nbsp;</span></span></p><p class="post-abstract"><h1 id="Scrapy文档笔记-3"><a href="#Scrapy文档笔记-3" class="headerlink" title="Scrapy文档笔记-3"></a>Scrapy文档笔记-3</h1><h2 id="Scrapy-shell"><a href="#Scrapy-shell" class="headerlink" title="Scrapy shell"></a>Scrapy shell</h2><p>The Scrapy shell是一个交互式shell,你可以用它来快速地debug你的scraping代码(主要是<strong>数据提取部分</strong>)而不必运行你的爬虫.</p>
<p>这个Shell主要用来<strong>测试XPath或者CSS表达式</strong>并且观察它们如何工作并且数据是如何从你爬取的web pages中提取出来的.更强大的是它允许你交互式地测试你写的表达式当你写爬虫代码时，从而避免每次更改代码时都运行爬虫来测试.</p>
<p>当你熟悉Scrapy shell你会发现它是一个强有力的工具在开发和测试你写的爬虫的时候.</p>
<h3 id="配置Shell"><a href="#配置Shell" class="headerlink" title="配置Shell"></a>配置Shell</h3><p>如果你安装了<strong>Ipython</strong>,那非常好，Scrapy会使用它而不是标准的Python控制台，因为Ipython更加强大而且有五颜六色的输出（:smile:）如果你没有安装Ipython，那么强烈推荐你安装Ipython(<strong>某茂林学长是Ipython的拥趸</strong>)</p>
<p>当然如果无法安装Ipython,bpython或者标准的python console也是可以的。</p>
<p>通过设置<code>SCRAPY_PYTHON_SHELL</code>环境变量或者在scrapy.cfg中修改配置文件来配置Scrapy Shell</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[settings]</span><br><span class="line">shell = ipython</span><br></pre></td></tr></table></figure>
<h3 id="启动shell"><a href="#启动shell" class="headerlink" title="启动shell"></a>启动shell</h3><p>通过shell命令运行Scrapy shell</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy shell &lt;url&gt;</span><br></pre></td></tr></table></figure>
<p>\<url>是你想要爬取的链接</url></p>
<p>shell也可以将爬取下来的网页保存为本地文件</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># UNIX-style</span><br><span class="line">scrapy shell ./path/to/file.html</span><br><span class="line">scrapy shell ../other/path/to/file.html</span><br><span class="line">scrapy shell /absolute/path/to/file.html</span><br><span class="line"></span><br><span class="line"># File URI</span><br><span class="line">scrapy shell file:///absolute/path/to/file.html</span><br></pre></td></tr></table></figure>
<blockquote>
<p>注意:</p>
<p>UNIX-style中，特别注意相对文件路径的使用，不要遗漏<code>./</code>或者<code>../</code></p>
</blockquote>
<h3 id="使用Shell"><a href="#使用Shell" class="headerlink" title="使用Shell"></a>使用Shell</h3><p>Scrapy Shell仅仅是一个常规的Python console，只是为了方便多提供了额外的快捷函数</p>
<h4 id="Available-Shortcuts"><a href="#Available-Shortcuts" class="headerlink" title="Available Shortcuts"></a>Available Shortcuts</h4><ul>
<li><code>shelp()</code> - 帮助选项</li>
<li><code>fetch(url[, redirect=True])</code> -根据给定的url获取新的response并相应地更新所有相关对象.You can optionaly ask for HTTP 3xx redirections to not be followed by passing <code>redirect=False</code></li>
<li><code>fetch(request)</code> - 根据给定的requests获取新的response<strong>并相应地更新所有相关对象</strong></li>
<li><code>view(response)</code> - 在本机的浏览器打开给定的 response。 其会在response的body中添加一个 [base]tag ，使得外部链接(例如图片及css)能正确显示。 注意，该操作会在本地创建一个临时文件，且该文件不会被自动删除</li>
</ul>
<h4 id="Available-Scrapy-objects"><a href="#Available-Scrapy-objects" class="headerlink" title="Available Scrapy objects"></a>Available Scrapy objects</h4><p>Scrapy shell自动从被下载的页面创建一些便利的对象,比如 <code>Response</code>对象和<code>Selector</code>对象(for both HTML and XML 内容)</p>
<ul>
<li><code>crawler</code> - 当前Crawler对象</li>
<li><code>spider</code> - 处理URL的spider,对没有Spider处理的URL则为一个Spider对象</li>
<li><code>request</code> - 最近获取到的页面的<code>Request</code>对象，可以使用<code>replace()</code>修改该request,或者使用<code>fetch()</code>快捷方式来获取新的request</li>
<li><code>response</code> - 包含最近获取到的页面的<code>Response</code>对象</li>
<li><code>sel</code> - 根据最近获取到的response构建的 Selector 对象</li>
<li><code>settings</code> - 当前的 <a href="https://docs.scrapy.org/en/latest/topics/settings.html#topics-settings" target="_blank" rel="noopener">Scrapy settings</a></li>
</ul>
<h3 id="Shell-会话示例"><a href="#Shell-会话示例" class="headerlink" title="Shell 会话示例"></a>Shell 会话示例</h3><p>下面是一个典型的shell会话示例，我们首先抓取 <a href="http://scrapy.org/" target="_blank" rel="noopener">http://scrapy.org</a> 页面，然后继续抓取 <a href="https://reddit.com/" target="_blank" rel="noopener">https://reddit.com</a> 页面。最后，我们修改（Reddit）请求方法为POST并重新获取它得到一个错误。我们通过在Windows中键入Ctrl-D（在Unix系统中）或Ctrl-Z结束会话。 </p>
<p>需要注意的是，由于爬取的页面不是静态页，内容会随着时间而修改， 因此例子中提取到的数据可能与您尝试的结果不同。 该例子的唯一目的是让您熟悉Scrapy shell。</p>
<p>首先，我们启动shell:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy shell &apos;http://scrapy.org&apos; --nolog</span><br></pre></td></tr></table></figure>
<p>然后，shell获取URL（使用Scrapy下载器）并打印可用对象和有用的快捷方式列表（您会注意到这些行都以 [s] 前缀开头）： </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[s] Available Scrapy objects:</span><br><span class="line">[s]   scrapy     scrapy module (contains scrapy.Request, scrapy.Selector, etc)</span><br><span class="line">[s]   crawler    &lt;scrapy.crawler.Crawler object at 0x0000029C9C734860&gt;</span><br><span class="line">[s]   item       &#123;&#125;</span><br><span class="line">[s]   request    &lt;GET http://scrapy.org&gt;</span><br><span class="line">[s]   response   &lt;200 https://scrapy.org/&gt;</span><br><span class="line">[s]   settings   &lt;scrapy.settings.Settings object at 0x0000029C9DA47828&gt;</span><br><span class="line">[s]   spider     &lt;DefaultSpider &apos;default&apos; at 0x29c9dcea2b0&gt;</span><br><span class="line">[s] Useful shortcuts:</span><br><span class="line">[s]   fetch(url[, redirect=True]) Fetch URL and update local objects (by default, redirects are folowed)</span><br><span class="line">[s]   fetch(req)                  Fetch a scrapy.Request and update local objects</span><br><span class="line">[s]   shelp()           Shell help (print this help)</span><br><span class="line">[s]   view(response)    View response in a browser</span><br></pre></td></tr></table></figure>
<p>之后，我们可以开始使用对象： </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; response.xpath(&apos;//title/text()&apos;).extract_first()</span><br><span class="line">&apos;Scrapy | A Fast and Powerful Scraping and Web Crawling Framework&apos;</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; fetch(&quot;http://reddit.com&quot;)</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; response.xpath(&apos;//title/text()&apos;).extract()</span><br><span class="line">[&apos;reddit: the front page of the internet&apos;]</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; request = request.replace(method=&quot;POST&quot;)</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; fetch(request)</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; response.status</span><br><span class="line">404</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; from pprint import pprint</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; pprint(response.headers)</span><br><span class="line">&#123;&apos;Accept-Ranges&apos;: [&apos;bytes&apos;],</span><br><span class="line"> &apos;Cache-Control&apos;: [&apos;max-age=0, must-revalidate&apos;],</span><br><span class="line"> &apos;Content-Type&apos;: [&apos;text/html; charset=UTF-8&apos;],</span><br><span class="line"> &apos;Date&apos;: [&apos;Thu, 08 Dec 2016 16:21:19 GMT&apos;],</span><br><span class="line"> &apos;Server&apos;: [&apos;snooserv&apos;],</span><br><span class="line"> &apos;Set-Cookie&apos;: [&apos;loid=KqNLou0V9SKMX4qb4n; Domain=reddit.com; Max-Age=63071999; Path=/; expires=Sat, 08-Dec-2018 16:21:19 GMT; secure&apos;,</span><br><span class="line">                &apos;loidcreated=2016-12-08T16%3A21%3A19.445Z; Domain=reddit.com; Max-Age=63071999; Path=/; expires=Sat, 08-Dec-2018 16:21:19 GMT; secure&apos;,</span><br><span class="line">                &apos;loid=vi0ZVe4NkxNWdlH7r7; Domain=reddit.com; Max-Age=63071999; Path=/; expires=Sat, 08-Dec-2018 16:21:19 GMT; secure&apos;,</span><br><span class="line">                &apos;loidcreated=2016-12-08T16%3A21%3A19.459Z; Domain=reddit.com; Max-Age=63071999; Path=/; expires=Sat, 08-Dec-2018 16:21:19 GMT; secure&apos;],</span><br><span class="line"> &apos;Vary&apos;: [&apos;accept-encoding&apos;],</span><br><span class="line"> &apos;Via&apos;: [&apos;1.1 varnish&apos;],</span><br><span class="line"> &apos;X-Cache&apos;: [&apos;MISS&apos;],</span><br><span class="line"> &apos;X-Cache-Hits&apos;: [&apos;0&apos;],</span><br><span class="line"> &apos;X-Content-Type-Options&apos;: [&apos;nosniff&apos;],</span><br><span class="line"> &apos;X-Frame-Options&apos;: [&apos;SAMEORIGIN&apos;],</span><br><span class="line"> &apos;X-Moose&apos;: [&apos;majestic&apos;],</span><br><span class="line"> &apos;X-Served-By&apos;: [&apos;cache-cdg8730-CDG&apos;],</span><br><span class="line"> &apos;X-Timer&apos;: [&apos;S1481214079.394283,VS0,VE159&apos;],</span><br><span class="line"> &apos;X-Ua-Compatible&apos;: [&apos;IE=edge&apos;],</span><br><span class="line"> &apos;X-Xss-Protection&apos;: [&apos;1; mode=block&apos;]&#125;</span><br><span class="line">&gt;&gt;&gt;</span><br></pre></td></tr></table></figure>
<h3 id="在spider中调用shell来查看response"><a href="#在spider中调用shell来查看response" class="headerlink" title="在spider中调用shell来查看response"></a>在spider中调用shell来查看response</h3><p>有时您想在spider的某个位置中查看被处理的response， 以确认您期望的response到达特定位置。</p>
<p>这可以通过 scrapy.shell.inspect_response 函数来实现。</p>
<p>以下是如何在spider中调用该函数的例子</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MySpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">"myspider"</span></span><br><span class="line">    start_urls = [</span><br><span class="line">        <span class="string">"http://example.com"</span>,</span><br><span class="line">        <span class="string">"http://example.org"</span>,</span><br><span class="line">        <span class="string">"http://example.net"</span>,</span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="comment"># We want to inspect one specific response.</span></span><br><span class="line">        <span class="keyword">if</span> <span class="string">".org"</span> <span class="keyword">in</span> response.url:</span><br><span class="line">            <span class="keyword">from</span> scrapy.shell <span class="keyword">import</span> inspect_response</span><br><span class="line">            inspect_response(response, self)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Rest of parsing code.</span></span><br></pre></td></tr></table></figure>
<p>当运行spider时，您将得到类似下列的输出:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">2014-01-23 17:48:31-0400 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET http://example.com&gt; (referer: None)</span><br><span class="line">2014-01-23 17:48:31-0400 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET http://example.org&gt; (referer: None)</span><br><span class="line">[s] Available Scrapy objects:</span><br><span class="line">[s]   crawler    &lt;scrapy.crawler.Crawler object at 0x1e16b50&gt;</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">&gt;&gt;&gt; response.url</span><br><span class="line">&apos;http://example.org&apos;</span><br></pre></td></tr></table></figure>
<p>接着测试提取代码:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; response.xpath(&apos;//h1[@class=&quot;fn&quot;]&apos;)</span><br><span class="line">[]</span><br></pre></td></tr></table></figure>
<p>您可以在Web浏览器中打开response，看看它是否是您期望的response：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; view(response)</span><br><span class="line">True</span><br></pre></td></tr></table></figure>
<p>最后您可以点击Ctrl-D(Windows下Ctrl-Z)来退出终端，恢复爬取:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; ^D</span><br><span class="line">2014-01-23 17:50:03-0400 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET http://example.net&gt; (referer: None)</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>请注意，您不能在这里使用 <a href="https://oner-wv.gitbooks.io/scrapy_zh/content/%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/scrapy%E7%BB%88%E7%AB%AF.html" target="_blank" rel="noopener"><code>fetch</code></a> 快捷命令，因为Scrapy引擎被shell阻止。然而，在你离开shell之后，spider会继续爬到它停止的地方，如上图所示。</p>
<p><a href="https://docs.scrapy.org/en/latest/topics/shell.html#topics-shell" target="_blank" rel="noopener">参考文档-EN</a></p>
<p><a href="https://oner-wv.gitbooks.io/scrapy_zh/content/%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/scrapy%E7%BB%88%E7%AB%AF.html" target="_blank" rel="noopener">参考文档-ZH</a></p>
</p></div><div class="share"><span>分享到</span>&nbsp;<span class="soc"><a href="javascript:(function(){EN_CLIP_HOST='http://www.evernote.com';try{var%20x=document.createElement('SCRIPT');x.type='text/javascript';x.src=EN_CLIP_HOST+'/public/bookmarkClipper.js?'+(new%20Date().getTime()/100000);document.getElementsByTagName('head')[0].appendChild(x);}catch(e){location.href=EN_CLIP_HOST+'/clip.action?url='+encodeURIComponent(location.href)+'&amp;title='+encodeURIComponent(document.title);}})();" ref="nofollow" target="_blank" class="fa fa-bookmark"></a></span><span class="soc"><a href="javascript:void((function(s,d,e){try{}catch(e){}var f='http://service.weibo.com/share/share.php?',u=d.location.href,p=['url=',e(u),'&amp;title=',e(d.title),'&amp;appkey=2924220432'].join('');function a(){if(!window.open([f,p].join(''),'mb',['toolbar=0,status=0,resizable=1,width=620,height=450,left=',(s.width-620)/2,',top=',(s.height-450)/2].join('')))u.href=[f,p].join('');};if(/Firefox/.test(navigator.userAgent)){setTimeout(a,0)}else{a()}})(screen,document,encodeURIComponent));" class="fa fa-weibo"></a></span><span class="soc"><a href="http://twitter.com/home?status=http://yoursite.com/2018/05/29/Scrapy食用指南3/%20Ginger's blog%20Scrapy食用指南3" class="fa fa-twitter"></a></span></div><div class="pagination"><p class="clearfix"><span class="pre pagbuttons"><a role="navigation" href="/2018/05/30/Scrapy食用指南4/" title="Scrapy食用指南4"><i class="fa fa-angle-double-left"></i>&nbsp;上一篇: Scrapy食用指南4</a></span><span>&nbsp;</span><span class="next pagbuttons"><a role="navigation" href="/2018/05/28/外科手术队伍/" title="外科手术队伍">下一篇: 外科手术队伍&nbsp;<i class="fa fa-angle-double-right"></i></a></span></p></div></div></div></div><div class="visible-xs site-bottom-footer"><footer><p>&copy;&nbsp;2018&nbsp;<a target="_blank" href="http://yoursite.com" rel="noopener noreferrer">1-riverfish</a></p><p>Theme&nbsp;<a target="_blank" href="https://github.com/SumiMakito/hexo-theme-typography" rel="noopener noreferrer">Typography</a>&nbsp;by&nbsp;<a target="_blank" href="https://www.keep.moe" rel="noopener noreferrer">Makito</a></p><p>Proudly published with&nbsp;<a target="_blank" href="https://hexo.io" rel="noopener noreferrer">Hexo</a></p></footer></div></div></div></div><script src="/js/jquery-3.1.0.min.js"></script><script src="/js/bootstrap.min.js"></script><script src="/js/jquery-migrate-1.2.1.min.js"></script><script src="/js/jquery.appear.js"></script><script src="/js/google-analytics.js"></script><script src="/js/typography.js"></script></body></html>