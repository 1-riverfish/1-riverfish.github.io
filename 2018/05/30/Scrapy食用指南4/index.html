<!DOCTYPE html><html lang="zh-CN"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="author" content="1-riverfish"><title>Scrapy食用指南4 · Ginger's blog</title><meta name="description" content="Scrapy文档笔记-4提取数据学习提取数据的最好的方式是使用Scrapy shell的选择器,运行:
1scrapy shell &amp;apos;http://quotes.toscrape.com/page/1&amp;apos;

注意:
当你在终端运行Scrapy时，请一定记得给url地址加上引号，否则"><meta name="keywords" content=""><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="renderer" content="webkit"><link rel="short icon" href="/images/favicon.png" type="image/x-icon"><link rel="stylesheet" href="/css/bootstrap.min.css"><link rel="stylesheet" href="/css/font-awesome.min.css"><link rel="stylesheet" href="/css/style.css"><link rel="alternate" type="application/atom+xml" title="ATOM 1.0" href="/atom.xml"></head><body><div id="stage" class="container"><div class="row"><div id="side-bar" class="col-sm-3 col-xs-12 side-container invisible"><div class="vertical-text site-title"><h3 tabindex="-1" class="site-title-small"><a href="/" class="a-title">Share&amp;Joy</a></h3><h1 tabindex="-1" class="site-title-large"><a href="/" class="a-title">Ginger' Blog</a></h1><!--h6(onclick="triggerSiteNav()") Trigger--></div><br class="visible-lg visible-md visible-sm"><div id="site-nav" class="site-title-links"><ul><li><a href="/">首页</a></li><li><a href="/archives">归档</a></li><li><a href="/tags">标签</a></li><li class="soc"><a href="https://github.com/1-riverfish" target="_blank" rel="noopener noreferrer"><i class="fa fa-github">&nbsp;</i></a><a href="http://yoursite.com/atom.xml" target="_blank" rel="noopener noreferrer"><i class="fa fa-rss">&nbsp;</i></a></li></ul><div class="visible-lg visible-md visible-sm site-nav-footer"><br class="site-nav-footer-br"><footer><p>&copy;&nbsp;2018&nbsp;<a target="_blank" href="http://yoursite.com" rel="noopener noreferrer">1-riverfish</a></p><p>Theme&nbsp;<a target="_blank" href="https://github.com/SumiMakito/hexo-theme-typography" rel="noopener noreferrer">Typography</a>&nbsp;by&nbsp;<a target="_blank" href="https://www.keep.moe" rel="noopener noreferrer">Makito</a></p><p>Proudly published with&nbsp;<a target="_blank" href="https://hexo.io" rel="noopener noreferrer">Hexo</a></p></footer></div></div></div><div id="main-container" class="col-sm-9 col-xs-12 main-container invisible"><div class="autopagerize_page_element"><div class="content"><div class="post-page"><div class="post-container"><p class="post-title"><a>Scrapy食用指南4</a></p><p class="post-meta"><span class="date meta-item">发布于&nbsp;2018-05-30</span><span class="meta-item"><i class="fa fa-tag"></i><span>&nbsp;</span><a href="/tags/Scrapy/" title="Scrapy" class="a-tag">Scrapy</a><span>&nbsp;</span></span></p><p class="post-abstract"><h1 id="Scrapy文档笔记-4"><a href="#Scrapy文档笔记-4" class="headerlink" title="Scrapy文档笔记-4"></a>Scrapy文档笔记-4</h1><h2 id="提取数据"><a href="#提取数据" class="headerlink" title="提取数据"></a>提取数据</h2><p>学习提取数据的最好的方式是使用<code>Scrapy shell</code>的选择器,运行:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy shell &apos;http://quotes.toscrape.com/page/1&apos;</span><br></pre></td></tr></table></figure>
<blockquote>
<p>注意:</p>
<p>当你在终端运行Scrapy时，请一定记得给url地址加上引号，否则包含参数的url(例如<code>&amp;</code>字符)会导致Scrapy运行失败。</p>
<p>在Windows上请记得使用双引号:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&gt;scrapy shell &quot;http://quotes.toscrape.com/page/1/&quot;</span><br><span class="line">&gt;</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure>
</blockquote>
<p>你会看到类似</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">2018-05-30 15:27:22 [scrapy.core.engine] DEBUG: Crawled (200) &lt;GET http://quotes.toscrape.com/page/1/&gt; (referer: None)</span><br><span class="line">[s] Available Scrapy objects:</span><br><span class="line">[s]   scrapy     scrapy module (contains scrapy.Request, scrapy.Selector, etc)</span><br><span class="line">[s]   crawler    &lt;scrapy.crawler.Crawler object at 0x0000017F75D44828&gt;</span><br><span class="line">[s]   item       &#123;&#125;</span><br><span class="line">[s]   request    &lt;GET http://quotes.toscrape.com/page/1/&gt;</span><br><span class="line">[s]   response   &lt;200 http://quotes.toscrape.com/page/1/&gt;</span><br><span class="line">[s]   settings   &lt;scrapy.settings.Settings object at 0x0000017F77086860&gt;</span><br><span class="line">[s]   spider     &lt;DefaultSpider &apos;default&apos; at 0x17f7732c278&gt;</span><br><span class="line">[s] Useful shortcuts:</span><br><span class="line">[s]   fetch(url[, redirect=True]) Fetch URL and update local objects (by default, redirects are followed)</span><br><span class="line">[s]   fetch(req)                  Fetch a scrapy.Request and update local objects</span><br><span class="line">[s]   shelp()           Shell help (print this help)</span><br><span class="line">[s]   view(response)    View response in a browser</span><br><span class="line">&gt;&gt;&gt;</span><br></pre></td></tr></table></figure>
<p>使用shell,你可以通过使用带有response对象的CSS</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; response.css(&apos;title&apos;)</span><br><span class="line">[&lt;Selector xpath=&apos;descendant-or-self::title&apos; data=&apos;&lt;title&gt;Quotes to Scrape&lt;/title&gt;&apos;&gt;]</span><br></pre></td></tr></table></figure>
<p>运行<code>response.css(&#39;title&#39;)</code>的结果是一个名为<code>SelectorList</code>的类似列表的对象，它表示包含XML/HTML元素的<code>Selector</code>对象列表，允许您运行进一步的查询以精细选择或提取数据。</p>
<p>要从上边的标题中提取文本，您可以:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; response.css(&apos;title::text&apos;).extract()</span><br><span class="line">[&apos;Quotes to Scrape&apos;]</span><br></pre></td></tr></table></figure>
<p>这里要注意两件事</p>
<p>一是我们在CSS查询中添加了<code>::text</code>,这意味着我们只想在<code>&lt;title&gt;</code>元素中选择文本元素。如果我们不指定<code>::text</code>,我们将获得完整的 title 元素，包括其标签</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; response.css(&quot;title&quot;).extract()</span><br><span class="line">[&apos;&lt;title&gt;Quotes to Scrape&lt;/title&gt;&apos;]</span><br></pre></td></tr></table></figure>
<p>另一件事是调用<code>.extract()</code>的结果是一个列表，因为我们处理的是<code>SelectorList</code>的一个实例。如果你知道你只是想要第一个结果时，可以输入以下命令</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; response.css(&quot;title::text&quot;).extract_first()</span><br><span class="line">&apos;Quotes to Scrape&apos;</span><br></pre></td></tr></table></figure>
<p>你也可以这样做:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; response.css(&quot;title::text&quot;)[0].extract()</span><br><span class="line">&apos;Quotes to Scrape&apos;</span><br></pre></td></tr></table></figure>
<p>但是使用<code>.extract_first()</code>会避免<code>IndexError</code>,并且在找不到与选择匹配的元素时返回<code>None</code>。</p>
<p>这里有一个经验:对于大多数爬虫代码，你希望它的容错性比较高，因为在被爬取的页面上有时候会找不到我们想要的数据。所以即使有一部分没有被爬取到，你可以至少获得一些数据。</p>
<p>除了<code>extract</code>和<code>extract_first</code>方法之外，还可以使用<code>re</code>方法使用正则表达式进行提取</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; response.css(&quot;title::text&quot;).re(r&apos;Quotes.*&apos;)</span><br><span class="line">[&apos;Quotes to Scrape&apos;]</span><br><span class="line">&gt;&gt;&gt; response.css(&quot;title::text&quot;).re(r&apos;Q\w+&apos;)</span><br><span class="line">[&apos;Quotes&apos;]</span><br><span class="line">&gt;&gt;&gt; response.css(&quot;title::text&quot;).re(r&apos;(\w+) (\w+)&apos;)</span><br><span class="line">[&apos;Quotes&apos;, &apos;to&apos;]</span><br><span class="line">&gt;&gt;&gt; response.css(&quot;title::text&quot;).re(r&apos;(\w+) to (\w+)&apos;)</span><br><span class="line">[&apos;Quotes&apos;, &apos;Scrape&apos;]</span><br></pre></td></tr></table></figure>
<p>为了找到正确的CSS选择器使用，可以使用<code>view(response)</code>.也可以使用浏览器开发人员工具或拓展(如 Firebug  <strong>下一篇教程会详细写Firebug</strong>).</p>
<p>Selector Gadget也是一个很好的工具，可以快速找到CSS选择器的视觉选择元素，适用于许多浏览器.</p>
<h3 id="XPath简介"><a href="#XPath简介" class="headerlink" title="XPath简介"></a>XPath简介</h3><p>除了CSS，Scrapy选择器也支持使用XPath表达式</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; response.xpath(&quot;//title&quot;)</span><br><span class="line">[&lt;Selector xpath=&apos;//title&apos; data=&apos;&lt;title&gt;Quotes to Scrape&lt;/title&gt;&apos;&gt;]</span><br></pre></td></tr></table></figure>
<p>XPath表达式非常强大并且是 Scrapy Selectors的基础.事实上，CSS选择器的底层实现是由XPath来完成(待商榷).如果您仔细阅读在 shell 中的选择器对象的文本表示您将会看到它。 <strong>(selector对象在这个Scrapy版本没有显示出来,即sel)</strong></p>
<p>虽然可能不像CSS选择器那样流行，XPath 表达式提供了更多的功能，因为除了导航结构之外，它还可以查看内容。使用 XPath，您可以选择以下内容：选择包含文本“下一页”的链接。这使得 XPath 非常适合于抓取的任务，我们鼓励您学习 XPath ，即使您已经知道如何构造CSS选择器，它将使抓取更容易。</p>
<p>我们不会在这里介绍 XPath 的很多，但是你可以阅读更多关于 <a href="https://doc.scrapy.org/en/1.3/topics/selectors.html#topics-selectors" target="_blank" rel="noopener">使用 XPath 与 Scrapy 选择器?</a> 。要了解有关 XPath 的更多信息，我们建议 <a href="http://zvon.org/comp/r/tut-XPath_1.html" target="_blank" rel="noopener">本教程通过示例学习 XPath</a> ，以及 <a href="http://plasmasturm.org/log/xpath101/" target="_blank" rel="noopener">本教程学习如何在XPath中思考</a> 。</p>
<h3 id="提取-quotes-和-authors"><a href="#提取-quotes-和-authors" class="headerlink" title="提取 quotes 和 authors"></a>提取 quotes 和 authors</h3><p>现在您已经对选择（select）和提取（extract）有一定的了解，让我们通过编写代码从网页提取quote来完成我们的爬虫。 </p>
<p><a href="http://quotes.toscrape.com中的每个" target="_blank" rel="noopener">http://quotes.toscrape.com中的每个</a> quote  都由如下所示的HTML元素表示</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"quote"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">span</span> <span class="attr">class</span>=<span class="string">"text"</span>&gt;</span>“The world as we have created it is a process of our</span><br><span class="line">    thinking. It cannot be changed without changing our thinking.”<span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">span</span>&gt;</span></span><br><span class="line">        by <span class="tag">&lt;<span class="name">small</span> <span class="attr">class</span>=<span class="string">"author"</span>&gt;</span>Albert Einstein<span class="tag">&lt;/<span class="name">small</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"/author/Albert-Einstein"</span>&gt;</span>(about)<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">span</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span> <span class="attr">class</span>=<span class="string">"tags"</span>&gt;</span></span><br><span class="line">        Tags:</span><br><span class="line">        <span class="tag">&lt;<span class="name">a</span> <span class="attr">class</span>=<span class="string">"tag"</span> <span class="attr">href</span>=<span class="string">"/tag/change/page/1/"</span>&gt;</span>change<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">a</span> <span class="attr">class</span>=<span class="string">"tag"</span> <span class="attr">href</span>=<span class="string">"/tag/deep-thoughts/page/1/"</span>&gt;</span>deep-thoughts<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">a</span> <span class="attr">class</span>=<span class="string">"tag"</span> <span class="attr">href</span>=<span class="string">"/tag/thinking/page/1/"</span>&gt;</span>thinking<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">a</span> <span class="attr">class</span>=<span class="string">"tag"</span> <span class="attr">href</span>=<span class="string">"/tag/world/page/1/"</span>&gt;</span>world<span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>现在让我们打开scrapy shell来探索一下如何提取我们想要的数据</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ scrapy shell &quot;http://quotes.toscrape.com&quot;</span><br></pre></td></tr></table></figure>
<p>我们得到一个带有 HTML 元素的选择器列表</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; response.css(&quot;div.quote&quot;)</span><br><span class="line">[&lt;Selector xpath=&quot;descendant-or-self::div[@class and contains(concat(&apos; &apos;, normalize-space(@class), &apos; &apos;), &apos; quote &apos;)]&quot; data=&apos;&lt;div class=&quot;quote&quot; itemscope itemtype=&quot;h&apos;&gt;, &lt;Selector xpath=&quot;descendant-or-self::div[@class and cont</span><br><span class="line">ains(concat(&apos; &apos;, normalize-space(@class), &apos; &apos;), &apos; quote &apos;)]&quot; data=&apos;&lt;div class=&quot;quote&quot; itemscope itemtype=&quot;h&apos;&gt;, &lt;Selector xpath=&quot;descendant-or-self::div[@class and contains(concat(&apos; &apos;, normalize-space(@class), &apos; &apos;), &apos; quote &apos;</span><br><span class="line">)]&quot; data=&apos;&lt;div class=&quot;quote&quot; itemscope itemtype=&quot;h&apos;&gt;, &lt;Selector xpath=&quot;descendant-or-self::div[@class and contains(concat(&apos; &apos;, normalize-space(@class), &apos; &apos;), &apos; quote &apos;)]&quot; data=&apos;&lt;div class=&quot;quote&quot; itemscope itemtype=&quot;h&apos;&gt;, &lt;Se</span><br><span class="line">lector xpath=&quot;descendant-or-self::div[@class and contains(concat(&apos; &apos;, normalize-space(@class), &apos; &apos;), &apos; quote &apos;)]&quot; data=&apos;&lt;div class=&quot;quote&quot; itemscope itemtype=&quot;h&apos;&gt;, &lt;Selector xpath=&quot;descendant-or-self::div[@class and contains</span><br><span class="line">(concat(&apos; &apos;, normalize-space(@class), &apos; &apos;), &apos; quote &apos;)]&quot; data=&apos;&lt;div class=&quot;quote&quot; itemscope itemtype=&quot;h&apos;&gt;, &lt;Selector xpath=&quot;descendant-or-self::div[@class and contains(concat(&apos; &apos;, normalize-space(@class), &apos; &apos;), &apos; quote &apos;)]&quot;</span><br><span class="line">data=&apos;&lt;div class=&quot;quote&quot; itemscope itemtype=&quot;h&apos;&gt;, &lt;Selector xpath=&quot;descendant-or-self::div[@class and contains(concat(&apos; &apos;, normalize-space(@class), &apos; &apos;), &apos; quote &apos;)]&quot; data=&apos;&lt;div class=&quot;quote&quot; itemscope itemtype=&quot;h&apos;&gt;, &lt;Select</span><br><span class="line">or xpath=&quot;descendant-or-self::div[@class and contains(concat(&apos; &apos;, normalize-space(@class), &apos; &apos;), &apos; quote &apos;)]&quot; data=&apos;&lt;div class=&quot;quote&quot; itemscope itemtype=&quot;h&apos;&gt;, &lt;Selector xpath=&quot;descendant-or-self::div[@class and contains(con</span><br><span class="line">cat(&apos; &apos;, normalize-space(@class), &apos; &apos;), &apos; quote &apos;)]&quot; data=&apos;&lt;div class=&quot;quote&quot; itemscope itemtype=&quot;h&apos;&gt;]</span><br><span class="line">&gt;&gt;&gt;</span><br></pre></td></tr></table></figure>
<p>通过上面的查询返回的每个选择器允许我们对他们的子元素进行进一步查询。让我们将第一个选择器分配给一个变量，以便我们可以直接对特定的引用运行我们的CSS选择器： </p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; quote = response.css(&quot;div.quote&quot;)[0]</span><br></pre></td></tr></table></figure>
<p>现在，让我们使用刚刚创建的 <code>quote</code> 对象从该报价中提取 <code>title</code> ， <code>author</code> 和 <code>tags</code>:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; quote = response.css(&quot;div.quote&quot;)[0]</span><br><span class="line">&gt;&gt;&gt; title = quote.css(&quot;span.text::text&quot;).extract_first()</span><br><span class="line">&gt;&gt;&gt; title</span><br><span class="line">&apos;“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”&apos;</span><br><span class="line">&gt;&gt;&gt; author = response.css(&quot;small.author::text&quot;).extract_first()</span><br><span class="line">&gt;&gt;&gt; author</span><br><span class="line">&apos;Albert Einstein&apos;</span><br><span class="line">&gt;&gt;&gt; tags = response.css(&quot;a.tag::text&quot;).extract()</span><br><span class="line">&gt;&gt;&gt; tags</span><br><span class="line">[&apos;change&apos;, &apos;deep-thoughts&apos;, &apos;thinking&apos;, &apos;world&apos;, &apos;abilities&apos;, &apos;choices&apos;, &apos;inspirational&apos;, &apos;life&apos;, &apos;live&apos;, &apos;miracle&apos;, &apos;miracles&apos;, &apos;aliteracy&apos;, &apos;books&apos;, &apos;classic&apos;, &apos;humor&apos;, &apos;be-yourself&apos;, &apos;inspirational&apos;, &apos;adulthood&apos;, &apos;success</span><br><span class="line">&apos;, &apos;value&apos;, &apos;life&apos;, &apos;love&apos;, &apos;edison&apos;, &apos;failure&apos;, &apos;inspirational&apos;, &apos;paraphrased&apos;, &apos;misattributed-eleanor-roosevelt&apos;, &apos;humor&apos;, &apos;obvious&apos;, &apos;simile&apos;, &apos;love&apos;, &apos;inspirational&apos;, &apos;life&apos;, &apos;humor&apos;, &apos;books&apos;, &apos;reading&apos;, &apos;friendship&apos;, &apos;f</span><br><span class="line">riends&apos;, &apos;truth&apos;, &apos;simile&apos;]</span><br><span class="line">&gt;&gt;&gt;</span><br></pre></td></tr></table></figure>
<p>搞清楚如何提取每个位之后，我们现在可以遍历所有的引号元素，并将它们放在一起成为一个Python字典</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> quote <span class="keyword">in</span> response.css(<span class="string">"div.quote"</span>):</span><br><span class="line"><span class="meta">... </span>    title = quote.css(<span class="string">"span.text::text"</span>).extract_first()</span><br><span class="line"><span class="meta">... </span>    author = quote.css(<span class="string">"small.author::text"</span>).extract_first()</span><br><span class="line"><span class="meta">... </span>    tags = quote.css(<span class="string">"a.tag::text"</span>).extract()</span><br><span class="line"><span class="meta">... </span>    print(dict(text=title,author=author,tags=tags))</span><br><span class="line">...</span><br><span class="line">&#123;<span class="string">'text'</span>: <span class="string">'“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”'</span>, <span class="string">'author'</span>: <span class="string">'Albert Einstein'</span>, <span class="string">'tags'</span>: [<span class="string">'change'</span>, <span class="string">'deep-thoughts'</span>, <span class="string">'thinking'</span>, <span class="string">'world'</span>]&#125;</span><br><span class="line">&#123;<span class="string">'text'</span>: <span class="string">'“It is our choices, Harry, that show what we truly are, far more than our abilities.”'</span>, <span class="string">'author'</span>: <span class="string">'J.K. Rowling'</span>, <span class="string">'tags'</span>: [<span class="string">'abilities'</span>, <span class="string">'choices'</span>]&#125;</span><br><span class="line">&#123;<span class="string">'text'</span>: <span class="string">'“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”'</span>, <span class="string">'author'</span>: <span class="string">'Albert Einstein'</span>, <span class="string">'tags'</span>: [<span class="string">'inspirational'</span>, <span class="string">'life'</span>, <span class="string">'live'</span>, <span class="string">'miracl</span></span><br><span class="line"><span class="string">e'</span>, <span class="string">'miracles'</span>]&#125;</span><br><span class="line">&#123;<span class="string">'text'</span>: <span class="string">'“The person, be it gentleman or lady, who has not pleasure in a good novel, must be intolerably stupid.”'</span>, <span class="string">'author'</span>: <span class="string">'Jane Austen'</span>, <span class="string">'tags'</span>: [<span class="string">'aliteracy'</span>, <span class="string">'books'</span>, <span class="string">'classic'</span>, <span class="string">'humor'</span>]&#125;</span><br><span class="line">&#123;<span class="string">'text'</span>: <span class="string">"“Imperfection is beauty, madness is genius and it's better to be absolutely ridiculous than absolutely boring.”"</span>, <span class="string">'author'</span>: <span class="string">'Marilyn Monroe'</span>, <span class="string">'tags'</span>: [<span class="string">'be-yourself'</span>, <span class="string">'inspirational'</span>]&#125;</span><br><span class="line">&#123;<span class="string">'text'</span>: <span class="string">'“Try not to become a man of success. Rather become a man of value.”'</span>, <span class="string">'author'</span>: <span class="string">'Albert Einstein'</span>, <span class="string">'tags'</span>: [<span class="string">'adulthood'</span>, <span class="string">'success'</span>, <span class="string">'value'</span>]&#125;</span><br><span class="line">&#123;<span class="string">'text'</span>: <span class="string">'“It is better to be hated for what you are than to be loved for what you are not.”'</span>, <span class="string">'author'</span>: <span class="string">'André Gide'</span>, <span class="string">'tags'</span>: [<span class="string">'life'</span>, <span class="string">'love'</span>]&#125;</span><br><span class="line">&#123;<span class="string">'text'</span>: <span class="string">"“I have not failed. I've just found 10,000 ways that won't work.”"</span>, <span class="string">'author'</span>: <span class="string">'Thomas A. Edison'</span>, <span class="string">'tags'</span>: [<span class="string">'edison'</span>, <span class="string">'failure'</span>, <span class="string">'inspirational'</span>, <span class="string">'paraphrased'</span>]&#125;</span><br><span class="line">&#123;<span class="string">'text'</span>: <span class="string">"“A woman is like a tea bag; you never know how strong it is until it's in hot water.”"</span>, <span class="string">'author'</span>: <span class="string">'Eleanor Roosevelt'</span>, <span class="string">'tags'</span>: [<span class="string">'misattributed-eleanor-roosevelt'</span>]&#125;</span><br><span class="line">&#123;<span class="string">'text'</span>: <span class="string">'“A day without sunshine is like, you know, night.”'</span>, <span class="string">'author'</span>: <span class="string">'Steve Martin'</span>, <span class="string">'tags'</span>: [<span class="string">'humor'</span>, <span class="string">'obvious'</span>, <span class="string">'simile'</span>]&#125;</span><br></pre></td></tr></table></figure>
<h3 id="在我们的爬虫中提取数据"><a href="#在我们的爬虫中提取数据" class="headerlink" title="在我们的爬虫中提取数据"></a>在我们的爬虫中提取数据</h3><p>让我们回到爬虫，到现在为止它还没有提取任何特别的数据，只是将整个HTML页面保存到本地文件上，让我们将上面的提取逻辑集成到我们的爬虫中.</p>
<p>Scrapy 爬虫通常会生成许多包含从页面中提取的数据的字典。为此，我们在回调中使用 Python 的 <code>yield</code> 关键字，如下所示： </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">QuotesSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">"quotes"</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">start_requests</span><span class="params">(self)</span>:</span></span><br><span class="line">        urls = [</span><br><span class="line">            <span class="string">"http://quotes.toscrape.com/page/1/"</span>,</span><br><span class="line">            <span class="string">"http://quotes.toscrape.com/page/2/"</span>,</span><br><span class="line">        ]</span><br><span class="line">        <span class="keyword">for</span> url <span class="keyword">in</span> urls:</span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(url=url, callback=self.parse)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self,response)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> quote <span class="keyword">in</span> response.css(<span class="string">"div.quote"</span>):</span><br><span class="line">            <span class="keyword">yield</span> &#123;</span><br><span class="line">                <span class="string">'text'</span>:quote.css(<span class="string">'span.text::text'</span>).extract_first(),</span><br><span class="line">                <span class="string">'author'</span>:quote.css(<span class="string">"small.author::text"</span>).extract_first(),</span><br><span class="line">                <span class="string">'tags'</span>:quote.css(<span class="string">"a.tag::text"</span>).extract()</span><br><span class="line">            &#125;</span><br></pre></td></tr></table></figure>
<p>运行爬虫，你会得到类似下面的输出</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">2018-05-30 19:28:19 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 http://quotes.toscrape.com/page/1/&gt;</span><br><span class="line">&#123;&apos;text&apos;: &apos;“The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”&apos;, &apos;author&apos;: &apos;Albert Einstein&apos;, &apos;tags&apos;: [&apos;change&apos;, &apos;deep-thoughts&apos;, &apos;thinking&apos;, &apos;world&apos;]&#125;</span><br><span class="line">2018-05-30 19:28:19 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 http://quotes.toscrape.com/page/1/&gt;</span><br><span class="line">&#123;&apos;text&apos;: &apos;“It is our choices, Harry, that show what we truly are, far more than our abilities.”&apos;, &apos;author&apos;: &apos;J.K. Rowling&apos;, &apos;tags&apos;: [&apos;abilities&apos;, &apos;choices&apos;]&#125;</span><br><span class="line">2018-05-30 19:28:19 [scrapy.core.scraper] DEBUG: Scraped from &lt;200 http://quotes.toscrape.com/page/1/&gt;</span><br><span class="line">&#123;&apos;text&apos;: &apos;“There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”&apos;, &apos;author&apos;: &apos;Albert Einstein&apos;, &apos;tags&apos;: [&apos;inspirational&apos;, &apos;life&apos;, &apos;live&apos;, &apos;miracl</span><br><span class="line">e&apos;, &apos;miracles&apos;]&#125;</span><br></pre></td></tr></table></figure>
<h3 id="存储爬虫数据"><a href="#存储爬虫数据" class="headerlink" title="存储爬虫数据"></a>存储爬虫数据</h3><p>最简单的存储爬虫数据的方式是使用 <strong>Feed exports</strong>(在<strong>下下篇博客</strong>会详细说明)，使用下面的命令</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy crawl quotes -o quotes.json</span><br></pre></td></tr></table></figure>
<p>这将生成一个 <code>quotes.json</code> 文件，其中包含所有被抓取的项目，以 <a href="https://en.wikipedia.org/wiki/JSON" target="_blank" rel="noopener">JSON</a> 序列化。 </p>
<p>出于历史原因，Scrapy将附加到给定文件，而不是覆盖其内容。如果您运行这个命令两次，而且在第二次运行之前没有删除文件，您会得到一个broken的JSON文件。 </p>
<p>也可以使用其他格式的文件，例如 JSON Lines</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy crawl quotes -o quotes,j1</span><br></pre></td></tr></table></figure>
<p><a href="http://jsonlines.org/" target="_blank" rel="noopener">JSON Lines</a> 格式很有用，因为它是<strong>流式</strong>的，你可以<strong>轻松地添加新的记录</strong>到它。当你运行两次它<strong>没有相同的 JSON 问题</strong>。此外，由于<strong>每条记录都是单独的行</strong>，因此您可以处理大文件，而<strong>无需将所有内容都放在内存</strong>中，有像 <a href="https://stedolan.github.io/jq/" target="_blank" rel="noopener">JQ</a> 这样的工具可以帮助在命令行执行。</p>
<p>在小项目（如本教程中的一个）中，这应该足够了。但是，如果要对已抓取的 Item 执行更复杂的操作，则可以编写 <a href="https://oner-wv.gitbooks.io/scrapy_zh/content/%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/item%E7%AE%A1%E9%81%93.html#topics-item-pipeline" target="_blank" rel="noopener">Item Pipeline</a> 。在创建项目时，已经在 <code>tutorial / pipelines.py</code> 中为您创建了 Item Pipeline 的占位符文件。如果您只想存储被抓取的 Item ，您不需要实现任何 Item Pipeline。</p>
<h3 id="Following-links-跟进链接"><a href="#Following-links-跟进链接" class="headerlink" title="Following links(跟进链接)"></a>Following links(跟进链接)</h3><p>如果说我们不只是想从<a href="http://quotes.toscrape.com爬取前两页的内容，而是想爬取这个网站的所有页面，该怎么办？" target="_blank" rel="noopener">http://quotes.toscrape.com爬取前两页的内容，而是想爬取这个网站的所有页面，该怎么办？</a></p>
<p>现在您已经知道如何从网页中提取数据，让我们看看如何跟进他们的链接。</p>
<p>首先是提取我们要关注的网页的链接。检查我们的页面，我们可以看到有一个链接到下一页与下面的标记：</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">ul</span> <span class="attr">class</span>=<span class="string">"pager"</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">li</span> <span class="attr">class</span>=<span class="string">"next"</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"/page/2/"</span>&gt;</span>Next <span class="tag">&lt;<span class="name">span</span> <span class="attr">aria-hidden</span>=<span class="string">"true"</span>&gt;</span>&amp;rarr;<span class="tag">&lt;/<span class="name">span</span>&gt;</span><span class="tag">&lt;/<span class="name">a</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">ul</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>我们可以尝试在shell中提取它:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; response.css(&apos;li.next a&apos;).extract_first()</span><br><span class="line">&apos;&lt;a href=&quot;/page/2/&quot;&gt;Next &lt;span aria-hidden=&quot;true&quot;&gt;→&lt;/span&gt;&lt;/a&gt;&apos;</span><br></pre></td></tr></table></figure>
<p>上面的操作得到了锚( anchor )元素，但我们想要属性 href.为此，Scrapy支持了一个CSS拓展，允许让我们选择属性内容，如下所示:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;&gt;&gt; response.css(&quot;li.next a::attr(href)&quot;).extract_first()</span><br><span class="line">&apos;/page/2/&apos;</span><br></pre></td></tr></table></figure>
<p>现在我们的爬虫被修改为递归地跟进到下一页的链接，并从中提取数据:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">QuotesSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">"quotes"</span></span><br><span class="line">    start_urls = [</span><br><span class="line">        <span class="string">'http://quotes.toscrape.com/page/1/'</span>,</span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> quote <span class="keyword">in</span> response.css(<span class="string">'div.quote'</span>):</span><br><span class="line">            <span class="keyword">yield</span> &#123;</span><br><span class="line">                <span class="string">'text'</span>: quote.css(<span class="string">'span.text::text'</span>).extract_first(),</span><br><span class="line">                <span class="string">'author'</span>: quote.css(<span class="string">'span small::text'</span>).extract_first(),</span><br><span class="line">                <span class="string">'tags'</span>: quote.css(<span class="string">'div.tags a.tag::text'</span>).extract(),</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">        next_page = response.css(<span class="string">'li.next a::attr(href)'</span>).extract_first()</span><br><span class="line">        <span class="keyword">if</span> next_page <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">            next_page = response.urljoin(next_page)</span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(next_page, callback=self.parse)</span><br></pre></td></tr></table></figure>
<p>现在，在提取数据之后，<code>parse()</code> 方法寻找到下一页的链接，使用 <a href="https://oner-wv.gitbooks.io/scrapy_zh/content/%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/%E8%AF%B7%E6%B1%82%E5%92%8C%E5%93%8D%E5%BA%94.html#scrapy.http.Response.urljoin" target="_blank" rel="noopener"><code>urljoin()</code></a>方法构建一个完整的绝对 URL（因为链接可能是相对的），并产生一个新的请求到下一页，将其自身注册为回调，以处理下一页的数据提取，并保持抓取通过所有页面。</p>
<p>这里您可以看到 Scrapy 的跟进链接机制：当您在回调方法中产生一个请求时，当当前请求完成时 Scrapy 会调度要发送的请求，并注册一个回调方法。</p>
<p>使用它，您可以构建复杂的抓取工具，根据您定义的规则跟进链接，并根据访问的网页提取不同类型的数据。</p>
<p>在我们的示例中，它创建一个循环，所有的链接到下一页，<strong>直到它找不到一个可以抓取的博客，论坛和其他网站分页</strong>。</p>
<h3 id="创建请求的快捷方式"><a href="#创建请求的快捷方式" class="headerlink" title="创建请求的快捷方式"></a>创建请求的快捷方式</h3><p>你可以使用<code>response.follow</code>作为创建Request对象的快捷方式</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">QuotesSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">"quotes"</span></span><br><span class="line">    start_urls = [</span><br><span class="line">        <span class="string">'http://quotes.toscrape.com/page/1/'</span>,</span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> quote <span class="keyword">in</span> response.css(<span class="string">'div.quote'</span>):</span><br><span class="line">            <span class="keyword">yield</span> &#123;</span><br><span class="line">                <span class="string">'text'</span>: quote.css(<span class="string">'span.text::text'</span>).extract_first(),</span><br><span class="line">                <span class="string">'author'</span>: quote.css(<span class="string">'span small::text'</span>).extract_first(),</span><br><span class="line">                <span class="string">'tags'</span>: quote.css(<span class="string">'div.tags a.tag::text'</span>).extract(),</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">        next_page = response.css(<span class="string">'li.next a::attr(href)'</span>).extract_first()</span><br><span class="line">        <span class="keyword">if</span> next_page <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">            <span class="keyword">yield</span> response.follow(next_page, callback=self.parse)</span><br></pre></td></tr></table></figure>
<p>不同于scrapy.Request，<code>response.follow</code>直接支持相对 URLs,不需要调用urljoin.注意<code>response.follow</code>仅仅返回一个Request实例，你仍然需要调用yield去返回这个实例.</p>
<p>你也可以给<code>response.follow</code>传递一个选择器作为参数而不是一个字符串，这个选择器应该能够提取出正确的属性:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> href <span class="keyword">in</span> response.css(<span class="string">"li.next a::attr(href)"</span>):</span><br><span class="line">	<span class="keyword">yield</span> response.follow(a,callback=self.parse)</span><br></pre></td></tr></table></figure>
<p>对于<code>&lt;a&gt;</code>元素也存在着一个快捷方式:<code>response.follow</code>会自动使用他们的 href 属性，所以代码可以更短:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> a <span class="keyword">in</span> response.css(<span class="string">"li.next a"</span>):</span><br><span class="line">	<span class="keyword">yield</span> response.follow(a,callback=self.parse)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>注意:</p>
<p><code>response.follow(response.css(&#39;li.next a&#39;))</code> is not valid because<code>response.css</code> returns a list-like object with selectors for all results, not a single selector. A <code>for</code> loop like in the example above, or<code>response.follow(response.css(&#39;li.next a&#39;)[0])</code> is fine. </p>
</blockquote>
<h3 id="更多的示例和模式"><a href="#更多的示例和模式" class="headerlink" title="更多的示例和模式"></a>更多的示例和模式</h3><p>这里是另一个爬虫，用来说明回调和跟进链接，这一次是抓取作者信息： </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AuthorSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">'author'</span></span><br><span class="line"></span><br><span class="line">    start_urls = [<span class="string">'http://quotes.toscrape.com/'</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="comment"># follow links to author pages</span></span><br><span class="line">        <span class="keyword">for</span> href <span class="keyword">in</span> response.css(<span class="string">'.author + a::attr(href)'</span>):</span><br><span class="line">            <span class="keyword">yield</span> response.follow(href, self.parse_author)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># follow pagination links</span></span><br><span class="line">        <span class="keyword">for</span> href <span class="keyword">in</span> response.css(<span class="string">'li.next a::attr(href)'</span>):</span><br><span class="line">            <span class="keyword">yield</span> response.follow(href, self.parse)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_author</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">extract_with_css</span><span class="params">(query)</span>:</span></span><br><span class="line">            <span class="keyword">return</span> response.css(query).extract_first().strip()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">yield</span> &#123;</span><br><span class="line">            <span class="string">'name'</span>: extract_with_css(<span class="string">'h3.author-title::text'</span>),</span><br><span class="line">            <span class="string">'birthdate'</span>: extract_with_css(<span class="string">'.author-born-date::text'</span>),</span><br><span class="line">            <span class="string">'bio'</span>: extract_with_css(<span class="string">'.author-description::text'</span>),</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure>
<p>这个爬虫将从主页开始，它将跟进所有到作者页面的链接，并为每个链接调用 <code>parse_author</code> 回调方法，以及我们之前看到的 <code>parse</code> 回调的分页链接。</p>
<p><code>parse_author</code> 回调定义了一个帮助函数，用于从CSS查询中提取和清除数据，并生成带有作者数据的 Python dict。</p>
<p>另一个有趣的事情，这个爬虫演示的是，即使有很多来自同一作者的quote，我们不需要担心访问同一作者页面多次。<strong>默认情况下，Scrapy 会过滤掉已访问过的网址的重复请求，从而避免由于编程错误而导致服务器过多的问题。</strong>这可以通过设置 <a href="https://oner-wv.gitbooks.io/scrapy_zh/content/%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/%E8%AE%BE%E7%BD%AE.html#std:setting-DUPEFILTER_CLASS" target="_blank" rel="noopener"><code>DUPEFILTER_CLASS</code></a>进行配置。</p>
<p>希望现在您对如何使用 Scrapy 的跟进链接和回调的机制有一个很好的理解。</p>
<p>作为利用跟进链接的机制另一个示例爬虫，请查看一个通用爬虫 <a href="https://oner-wv.gitbooks.io/scrapy_zh/content/%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/%E7%88%AC%E8%99%AB.html#scrapy.spiders.CrawlSpider" target="_blank" rel="noopener"><code>CrawlSpider</code></a> 类，它实现了一个小规则引擎（small rules engine），您可以用它写你的爬虫。</p>
<p>此外，一个常见的模式是使用一个 <a href="https://oner-wv.gitbooks.io/scrapy_zh/content/%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/%E8%AF%B7%E6%B1%82%E5%92%8C%E5%93%8D%E5%BA%94.html#topics-request-response-ref-request-callback-arguments" target="_blank" rel="noopener">把额外的数据传递给回调函数的技巧</a> 来构建一个包含多个页面的数据的 Item。</p>
<h3 id="使用-spider-参数"><a href="#使用-spider-参数" class="headerlink" title="使用 spider 参数"></a>使用 spider 参数</h3><p>在运行爬虫时，可以使用 <code>-a</code> 选项为您的爬虫提供命令行参数：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy crawl quotes -o quotes-humor.json -a tag=humor</span><br></pre></td></tr></table></figure>
<p>这些参数传递给 Spider 的 <code>__init__</code> 方法，默认成为spider属性。</p>
<p>在此示例中，为 <code>tag</code> 参数提供的值将通过 <code>self.tag</code> 提供。您可以使用此方法使您的爬虫根据参数构建 URL来实现仅抓取带有特定tag的数据：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">import scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class QuotesSpider(scrapy.Spider):</span><br><span class="line">    name = &quot;quotes&quot;</span><br><span class="line"></span><br><span class="line">    def start_requests(self):</span><br><span class="line">        url = &apos;http://quotes.toscrape.com/&apos;</span><br><span class="line">        tag = getattr(self, &apos;tag&apos;, None)</span><br><span class="line">        if tag is not None:</span><br><span class="line">            url = url + &apos;tag/&apos; + tag</span><br><span class="line">        yield scrapy.Request(url, self.parse)</span><br><span class="line"></span><br><span class="line">    def parse(self, response):</span><br><span class="line">        for quote in response.css(&apos;div.quote&apos;):</span><br><span class="line">            yield &#123;</span><br><span class="line">                &apos;text&apos;: quote.css(&apos;span.text::text&apos;).extract_first(),</span><br><span class="line">                &apos;author&apos;: quote.css(&apos;span small a::text&apos;).extract_first(),</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">        next_page = response.css(&apos;li.next a::attr(href)&apos;).extract_first()</span><br><span class="line">        if next_page is not None:</span><br><span class="line">            next_page = response.urljoin(next_page)</span><br><span class="line">            yield scrapy.Request(next_page, self.parse)</span><br></pre></td></tr></table></figure>
<p>如果您向此爬虫传递 <code>tag=humor</code> 参数，您会注意到它只会访问 <code>humor</code> 标记中的网址，例如 <a href="http://quotes.toscrape.com/tag/humor%E3%80%82" target="_blank" rel="noopener">http://quotes.toscrape.com/tag/humor。</a></p>
<p>您可以 <a href="https://oner-wv.gitbooks.io/scrapy_zh/content/%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/%E7%88%AC%E8%99%AB.html#spiderargs" target="_blank" rel="noopener">在此处了解有关处理spider参数的更多信息</a></p>
<p><a href="https://docs.scrapy.org/en/latest/intro/tutorial.html" target="_blank" rel="noopener">参考文档-EN</a></p>
<p><a href="https://oner-wv.gitbooks.io/scrapy_zh/content/%E7%AC%AC%E4%B8%80%E6%AD%A5/scrapy%E5%85%A5%E9%97%A8%E6%95%99%E7%A8%8B.html" target="_blank" rel="noopener">参考文档-CH</a></p>
</p></div><div class="share"><span>分享到</span>&nbsp;<span class="soc"><a href="javascript:(function(){EN_CLIP_HOST='http://www.evernote.com';try{var%20x=document.createElement('SCRIPT');x.type='text/javascript';x.src=EN_CLIP_HOST+'/public/bookmarkClipper.js?'+(new%20Date().getTime()/100000);document.getElementsByTagName('head')[0].appendChild(x);}catch(e){location.href=EN_CLIP_HOST+'/clip.action?url='+encodeURIComponent(location.href)+'&amp;title='+encodeURIComponent(document.title);}})();" ref="nofollow" target="_blank" class="fa fa-bookmark"></a></span><span class="soc"><a href="javascript:void((function(s,d,e){try{}catch(e){}var f='http://service.weibo.com/share/share.php?',u=d.location.href,p=['url=',e(u),'&amp;title=',e(d.title),'&amp;appkey=2924220432'].join('');function a(){if(!window.open([f,p].join(''),'mb',['toolbar=0,status=0,resizable=1,width=620,height=450,left=',(s.width-620)/2,',top=',(s.height-450)/2].join('')))u.href=[f,p].join('');};if(/Firefox/.test(navigator.userAgent)){setTimeout(a,0)}else{a()}})(screen,document,encodeURIComponent));" class="fa fa-weibo"></a></span><span class="soc"><a href="http://twitter.com/home?status=http://yoursite.com/2018/05/30/Scrapy食用指南4/%20Ginger's blog%20Scrapy食用指南4" class="fa fa-twitter"></a></span></div><div class="pagination"><p class="clearfix"><span class="pre pagbuttons"><a role="navigation" href="/2018/06/01/Python3-Requests库爬取课表实战/" title="Python3 Requests库爬取课表实战"><i class="fa fa-angle-double-left"></i>&nbsp;上一篇: Python3 Requests库爬取课表实战</a></span><span>&nbsp;</span><span class="next pagbuttons"><a role="navigation" href="/2018/05/29/Scrapy食用指南3/" title="Scrapy食用指南3">下一篇: Scrapy食用指南3&nbsp;<i class="fa fa-angle-double-right"></i></a></span></p></div></div></div></div><div class="visible-xs site-bottom-footer"><footer><p>&copy;&nbsp;2018&nbsp;<a target="_blank" href="http://yoursite.com" rel="noopener noreferrer">1-riverfish</a></p><p>Theme&nbsp;<a target="_blank" href="https://github.com/SumiMakito/hexo-theme-typography" rel="noopener noreferrer">Typography</a>&nbsp;by&nbsp;<a target="_blank" href="https://www.keep.moe" rel="noopener noreferrer">Makito</a></p><p>Proudly published with&nbsp;<a target="_blank" href="https://hexo.io" rel="noopener noreferrer">Hexo</a></p></footer></div></div></div></div><script src="/js/jquery-3.1.0.min.js"></script><script src="/js/bootstrap.min.js"></script><script src="/js/jquery-migrate-1.2.1.min.js"></script><script src="/js/jquery.appear.js"></script><script src="/js/google-analytics.js"></script><script src="/js/typography.js"></script></body></html>